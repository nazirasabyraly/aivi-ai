import os
import shutil
import subprocess
import time
import logging
import random
import string
from fastapi import APIRouter, HTTPException, Depends, Request, Query
from fastapi.responses import FileResponse, StreamingResponse
from sqlalchemy.orm import Session
import yt_dlp
from yt_dlp.utils import ExtractorError, DownloadError
from pydantic import BaseModel

from ..dependencies import get_current_user
from ..models.user import User
from ..database import get_db
from ..services.auth_service import AuthService

log = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ YouTube
class ProxyConfig:
    def __init__(self):
        # Webshare –ø—Ä–æ–∫—Å–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        self.proxy_username = "ujaoszjw"
        self.proxy_password = "573z5xhtgbci"
        self.proxy_host = "p.webshare.io"
        self.proxy_port = 80
        
        # –°–ø–∏—Å–æ–∫ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç Webshare)
        self.proxy_endpoints = [
            f"http://{self.proxy_username}-rotate:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
            f"http://{self.proxy_username}-session-1:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
            f"http://{self.proxy_username}-session-2:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
            f"http://{self.proxy_username}-session-3:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
            f"http://{self.proxy_username}-session-4:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
        ]
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
        self.alternative_endpoints = [
            f"http://{self.proxy_username}-country-US:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
            f"http://{self.proxy_username}-country-GB:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
            f"http://{self.proxy_username}-country-DE:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
        ]
        
        # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–∫—Å–∏
        self.all_proxies = self.proxy_endpoints + self.alternative_endpoints

proxy_config = ProxyConfig()

recommend_router = APIRouter()
auth_service = AuthService()

AUDIO_CACHE_DIR = "audio_cache"
if not os.path.exists(AUDIO_CACHE_DIR):
    os.makedirs(AUDIO_CACHE_DIR)

def _get_yt_dlp_options(proxy_url: str = None):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ü–∏–∏ –¥–ª—è yt-dlp —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –±–æ—Ç-–¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ –ø—Ä–æ–∫—Å–∏."""
    ydl_opts = {
        'format': 'bestaudio[ext=m4a]/bestaudio/best',
        'outtmpl': os.path.join(AUDIO_CACHE_DIR, '%(id)s.%(ext)s'),
        'nocheckcertificate': True,
        'quiet': True,
        'no_warnings': True,
        'extract_audio': True,
        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'm4a'}],
        'logger': log,
        'retries': 2,
        'fragment_retries': 2,
        'socket_timeout': 45 if not proxy_url else 25,
        'geo_bypass': True,
        'geo_bypass_country': 'US',
        # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –±–æ—Ç–æ–≤
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'en-US,en;q=0.9,ru;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
        },
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –æ–ø—Ü–∏–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã YouTube
        'extractor_args': {
            'youtube': {
                'skip': ['dash', 'hls'],
                'player_client': ['android', 'web', 'ios', 'mweb'],
                'player_skip': ['configs'],
                'include_live_dash': False,
                'include_dash_manifest': False,
                'include_hls_manifest': False,
            }
        },
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        'no_check_certificate': True,
        'prefer_insecure': False,
        'ignoreerrors': False,
        'abort_on_unavailable_fragment': False,
        'keep_fragments': False,
        'buffersize': 1024,
        'http_chunk_size': 1024,
        'playlist_items': '1',
        'noplaylist': True,
        'writesubtitles': False,
        'writeautomaticsub': False,
        'allsubtitles': False,
        'listsubtitles': False,
        'subtitlesformat': 'best',
        'subtitleslangs': ['en'],
        'ignoreerrors': True,
        'no_color': True,
        'call_home': False,
        'sleep_interval': 1,
        'max_sleep_interval': 3,
        'sleep_interval_requests': 1,
        'sleep_interval_subtitles': 1,
    }
    
    if proxy_url:
        ydl_opts['proxy'] = proxy_url
        # –î–ª—è –ø—Ä–æ–∫—Å–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–∞–π–º–∞—É—Ç—ã
        ydl_opts['socket_timeout'] = 20
        ydl_opts['retries'] = 1
        ydl_opts['fragment_retries'] = 1
        log.info(f"üîó Using proxy: {proxy_url.split('@')[0].split('://')[-1]}@***")
    
    return ydl_opts

def _download_video_with_proxy(video_url: str, video_id: str, proxy_url: str):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∫—Å–∏."""
    log.info(f"üì° Downloading {video_id} with proxy...")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
    delay = random.uniform(2, 5)
    time.sleep(delay)
    
    ydl_opts = _get_yt_dlp_options(proxy_url=proxy_url)
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
            info_dict = ydl.extract_info(video_url, download=False)
            if not info_dict:
                raise DownloadError(f"Could not extract video info for {video_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–Ω–æ –ª–∏ –≤–∏–¥–µ–æ
            if info_dict.get('availability') == 'private':
                raise DownloadError(f"Video {video_id} is private")
            
            # –¢–µ–ø–µ—Ä—å —Å–∫–∞—á–∏–≤–∞–µ–º
            info_dict = ydl.extract_info(video_url, download=True)
            filename = ydl.prepare_filename(info_dict)
            base, _ = os.path.splitext(filename)
            final_filename = f"{base}.m4a"
            
            if os.path.exists(final_filename):
                log.info(f"‚úÖ Proxy download successful: {final_filename}")
                return final_filename
            else:
                raise DownloadError(f"File not created for {video_id}")
                
    except Exception as e:
        log.warning(f"‚ùå Proxy download failed for {video_id}: {str(e)}")
        raise e

def _download_video_direct(video_url: str, video_id: str):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ –±–µ–∑ –ø—Ä–æ–∫—Å–∏."""
    log.info(f"üîÑ Downloading {video_id} directly...")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É
    delay = random.uniform(3, 6)
    time.sleep(delay)
    
    ydl_opts = _get_yt_dlp_options()
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
            info_dict = ydl.extract_info(video_url, download=False)
            if not info_dict:
                raise DownloadError(f"Could not extract video info for {video_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–Ω–æ –ª–∏ –≤–∏–¥–µ–æ
            if info_dict.get('availability') == 'private':
                raise DownloadError(f"Video {video_id} is private")
            
            # –¢–µ–ø–µ—Ä—å —Å–∫–∞—á–∏–≤–∞–µ–º
            info_dict = ydl.extract_info(video_url, download=True)
            filename = ydl.prepare_filename(info_dict)
            base, _ = os.path.splitext(filename)
            final_filename = f"{base}.m4a"
            
            if os.path.exists(final_filename):
                log.info(f"‚úÖ Direct download successful: {final_filename}")
                return final_filename
            else:
                raise DownloadError(f"File not created for {video_id}")
                
    except Exception as e:
        log.warning(f"‚ùå Direct download failed for {video_id}: {str(e)}")
        raise e

def _download_with_fallback(video_url: str, video_id: str):
    """–ü—Ä–æ–±—É–µ—Ç —Å–∫–∞—á–∞—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ –ø—Ä–æ–∫—Å–∏, –∑–∞—Ç–µ–º –Ω–∞–ø—Ä—è–º—É—é."""
    
    # –°–Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ª—É—á—à–µ–π —Ä–æ—Ç–∞—Ü–∏–∏
    available_proxies = proxy_config.all_proxies.copy()
    random.shuffle(available_proxies)
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–∫—Å–∏
    for i, proxy_url in enumerate(available_proxies):
        try:
            log.info(f"üîÑ Attempt {i+1}/{len(available_proxies)}: Using proxy endpoint")
            return _download_video_with_proxy(video_url, video_id, proxy_url)
        except Exception as e:
            error_msg = str(e).lower()
            log.warning(f"‚ö†Ô∏è Proxy attempt {i+1} failed: {str(e)[:100]}...")
            
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞ –±–æ—Ç-–¥–µ—Ç–µ–∫—Ü–∏–∏, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–æ–∫—Å–∏
            if "sign in to confirm" not in error_msg and "bot" not in error_msg:
                continue
            
            # –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ –±–æ—Ç-–¥–µ—Ç–µ–∫—Ü–∏–∏, –∂–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –∏ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–∫—Å–∏
            if i < len(available_proxies) - 1:
                wait_time = random.uniform(3, 7)
                log.info(f"‚è≥ Bot detection error, waiting {wait_time:.1f}s before next proxy...")
                time.sleep(wait_time)
                continue
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å
    try:
        log.info("üîÑ All proxies failed, trying direct connection as last resort...")
        # –ñ–¥–µ–º –¥–æ–ª—å—à–µ –ø–µ—Ä–µ–¥ –ø—Ä—è–º—ã–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º
        time.sleep(random.uniform(5, 10))
        return _download_video_direct(video_url, video_id)
    except Exception as e:
        log.error(f"‚ùå Direct connection also failed: {str(e)}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        error_msg = str(e).lower()
        if "sign in to confirm" in error_msg or "bot" in error_msg:
            raise HTTPException(
                status_code=503, 
                detail="YouTube has temporarily blocked all our connections. Please try again in a few minutes."
            )
        elif "unavailable" in error_msg or "private" in error_msg:
            raise HTTPException(
                status_code=404, 
                detail="This video is not available for download."
            )
        elif "timeout" in error_msg or "connection" in error_msg:
            raise HTTPException(
                status_code=504, 
                detail="Connection timeout. Please try again."
            )
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"Failed to download video after all attempts. Error: {str(e)[:100]}"
            )

@recommend_router.get("/youtube-audio")
async def get_youtube_audio(video_id: str, db: Session = Depends(get_db), current_user: User = Depends(get_current_user)):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –æ—Ç–¥–∞–µ—Ç –∞—É–¥–∏–æ —Å YouTube —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫."""
    if not shutil.which('ffmpeg'):
        log.error("‚ùå FFMPEG NOT FOUND.", extra={"video_id": video_id})
        raise HTTPException(status_code=503, detail="Server is not configured for audio processing.")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
    cached_path = None
    for ext in ['m4a', 'mp3', 'webm']:
        potential_path = os.path.join(AUDIO_CACHE_DIR, f"{video_id}.{ext}")
        if os.path.exists(potential_path):
            cached_path = potential_path
            break
    
    if cached_path:
        log.info(f"‚úÖ Audio found in cache: {cached_path}", extra={"video_id": video_id})
        return FileResponse(cached_path, media_type="audio/mp4")

    try:
        video_url = f"https://www.youtube.com/watch?v={video_id}"
        audio_path = _download_with_fallback(video_url, video_id)

        if not audio_path or not os.path.exists(audio_path):
            raise HTTPException(status_code=500, detail="Failed to download audio.")

        def iterfile():
            with open(audio_path, mode="rb") as file_like:
                yield from file_like

        return StreamingResponse(iterfile(), media_type="audio/mp4")
        
    except HTTPException:
        # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º HTTP –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∫–∞–∫ –µ—Å—Ç—å
        raise
    except Exception as e:
        log.error(f"‚ùå CRITICAL ERROR in get_youtube_audio: {e}", extra={"video_id": video_id})
        raise HTTPException(status_code=500, detail=f"Failed to process audio: {str(e)}")


@recommend_router.get("/youtube-search")
async def search_youtube(q: str, max_results: int = 5):
    """–ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ –Ω–∞ YouTube —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∫—Å–∏."""
    
    # –ü—Ä–æ–±—É–µ–º —Å –ø—Ä–æ–∫—Å–∏ —Å–Ω–∞—á–∞–ª–∞
    for proxy_url in proxy_config.all_proxies:
        try:
            ydl_opts = {
                'format': 'bestaudio',
                'noplaylist': True,
                'default_search': 'ytsearch',
                'quiet': True,
                'no_warnings': True,
                'proxy': proxy_url,
                'socket_timeout': 15,
                'http_headers': {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                },
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                search_results = ydl.extract_info(f"ytsearch{max_results}:{q}", download=False)
                videos = []
                if 'entries' in search_results:
                    for entry in search_results['entries']:
                        videos.append({
                            "video_id": entry.get("id"),
                            "title": entry.get("title"),
                            "description": entry.get("description"),
                            "thumbnail": entry.get("thumbnail"),
                            "channel_title": entry.get("channel"),
                            "duration": entry.get("duration"),
                        })
                return {"results": videos}
                
        except Exception as e:
            log.warning(f"Search with proxy failed: {e}")
            continue
    
    # Fallback –±–µ–∑ –ø—Ä–æ–∫—Å–∏
    try:
        ydl_opts = {
            'format': 'bestaudio',
            'noplaylist': True,
            'default_search': 'ytsearch',
            'quiet': True,
            'no_warnings': True,
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            },
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            search_results = ydl.extract_info(f"ytsearch{max_results}:{q}", download=False)
            videos = []
            if 'entries' in search_results:
                for entry in search_results['entries']:
                    videos.append({
                        "video_id": entry.get("id"),
                        "title": entry.get("title"),
                        "description": entry.get("description"),
                        "thumbnail": entry.get("thumbnail"),
                        "channel_title": entry.get("channel"),
                        "duration": entry.get("duration"),
                    })
            return {"results": videos}
            
    except Exception as e:
        log.error(f"Error searching youtube: {e}")
        raise HTTPException(status_code=500, detail="Failed to search YouTube") 